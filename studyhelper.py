import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
import openai
from pathlib import Path
import hashlib
import base64
import random
import subprocess

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import docx2txt
import pdfplumber
from pptx import Presentation

###############################################################################
# NLTK ì„¤ì •
###############################################################################
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)
os.environ["NLTK_DATA"] = nltk_data_dir
nltk.data.path.append(nltk_data_dir)

try:
    nltk.data.find("tokenizers/punkt")
except LookupError:
    nltk.download("punkt", download_dir=nltk_data_dir)
try:
    nltk.data.find("corpora/stopwords")
except LookupError:
    nltk.download("stopwords", download_dir=nltk_data_dir)

korean_stopwords = ["ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ë”"]
english_stopwords = set(stopwords.words("english"))
final_stopwords = english_stopwords.union(set(korean_stopwords))

###############################################################################
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ & OpenAI API í‚¤ ì„¤ì •
###############################################################################
dotenv_path = Path(".env")
load_dotenv(dotenv_path=dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ë””ë²„ê·¸ìš©(ì„ íƒ): ì‹¤ì œë¡œ ë¡œë“œëœ í‚¤ê°€ ë¬´ì—‡ì¸ì§€ í™•ì¸
# ì£¼ì„ í•´ì œ ì‹œ, ì‹¤í–‰ ë¡œê·¸ì— API í‚¤ê°€ ë…¸ì¶œë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜í•˜ì„¸ìš”.
# print("DEBUG: OPENAI_API_KEY =", OPENAI_API_KEY)

if not OPENAI_API_KEY:
    st.error("ì„œë²„ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸ í•„ìš”)")
    st.stop()

# API í‚¤ ì„¤ì • (OpenAI í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì—†ì´ ì‚¬ìš©)
openai.api_key = OPENAI_API_KEY

###############################################################################
# OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ ê¸°ëŠ¥
###############################################################################
def migrate_openai_api():
    """
    ì˜ˆì „ ë²„ì „ì˜ openai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œ "no longer supported" ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´
    ìë™ìœ¼ë¡œ 'openai migrate' ëª…ë ¹ì„ ì‹œë„í•˜ëŠ” í•¨ìˆ˜.
    í˜„ì¬ openai>=1.0.0 í™˜ê²½ì—ì„œëŠ” ë³´í†µ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ.
    """
    try:
        result = subprocess.run(["openai", "migrate"], capture_output=True, text=True, check=True)
        st.info("OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•±ì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error("API ë§ˆì´ê·¸ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ 'openai migrate' ëª…ë ¹ì„ ì§ì ‘ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        st.stop()

###############################################################################
# GPT í•¨ìˆ˜
###############################################################################
def ask_gpt(messages, model_name="gpt-4", temperature=0.7):
    """
    OpenAI ChatCompletion APIë¥¼ í†µí•´ GPT ëª¨ë¸ì—ê²Œ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ë°›ëŠ” í•¨ìˆ˜.
    """
    try:
        resp = openai.ChatCompletion.create(
            model=model_name,
            messages=messages,
            temperature=temperature,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        error_message = str(e)
        # ì˜ˆì „ openai ë²„ì „ê³¼ í˜¸í™˜ë˜ì§€ ì•Šì„ ê²½ìš°, ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë„
        if "no longer supported" in error_message:
            migrate_openai_api()
        st.error(f"OpenAI API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ""

###############################################################################
# íŒŒì¼ ë¶„ì„ ë¡œì§ (PDF, PPTX, DOCX, ì´ë¯¸ì§€)
###############################################################################
def parse_docx(file_bytes):
    try:
        return docx2txt.process(BytesIO(file_bytes))
    except Exception:
        return "DOCX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_pdf(file_bytes):
    text_list = []
    try:
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text_list.append(page.extract_text() or "")
        return "\n".join(text_list)
    except Exception:
        return "PDF íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_ppt(file_bytes):
    text_list = []
    try:
        prs = Presentation(BytesIO(file_bytes))
        for slide in prs.slides:
            for shape in slide.shapes:
                if shape.has_text_frame:
                    text_list.append(shape.text)
        return "\n".join(text_list)
    except Exception:
        return "PPTX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_image(file_bytes):
    """
    í˜„ì¬ëŠ” ë‹¨ìˆœíˆ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ì§€ë§Œ,
    OCR ë“± ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    return "[ì´ë¯¸ì§€ íŒŒì¼] OCR ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€ ê°€ëŠ¥"

def analyze_file(fileinfo):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì˜ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ íŒŒì‹± í•¨ìˆ˜ í˜¸ì¶œ.
    """
    ext = fileinfo["ext"]
    data = fileinfo["data"]
    if ext == "docx":
        return parse_docx(data)
    elif ext == "pdf":
        return parse_pdf(data)
    elif ext == "pptx":
        return parse_ppt(data)
    elif ext in ["jpg", "jpeg", "png"]:
        return parse_image(data)
    else:
        return "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."

###############################################################################
# GPT ì±„íŒ… íƒ­
###############################################################################
def gpt_chat_tab():
    st.header("ğŸ“Œ GPT ì±„íŒ…")
    st.info("""
        **[GPT ì±„íŒ… ì‚¬ìš©ë²• ì•ˆë‚´]**
        1. ì•„ë˜ì˜ íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­ì—ì„œ PDF, PPTX, DOCX, JPG, PNG íŒŒì¼ì„ ì„ íƒí•˜ë©´ íŒŒì¼ ë‚´ìš©ì´ ìë™ ë¶„ì„ë©ë‹ˆë‹¤.
        2. íŒŒì¼ ë¶„ì„ í›„, ì±„íŒ… ê¸°ë¡ì— ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.
        3. í•˜ë‹¨ì˜ ë©”ì‹œì§€ ì…ë ¥ë€ì— ì§ˆë¬¸ì„ ì‘ì„±í•˜ë©´ ChatGPTê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
        """)
    
    # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì±„íŒ… ë¡œê·¸ ë³´ê´€
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    
    # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for msg in st.session_state.chat_messages:
        role, content = msg["role"], msg["content"]
        with st.chat_message(role):
            st.write(content)
    
    # íŒŒì¼ ì—…ë¡œë“œ í›„ ìë™ ë¶„ì„
    uploaded_files = st.file_uploader(
        "íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/PPTX/DOCX/ì´ë¯¸ì§€ ì§€ì›)",
        type=["pdf", "pptx", "docx", "jpg", "png"],
        accept_multiple_files=True
    )
    if uploaded_files:
        for uf in uploaded_files:
            file_bytes = uf.getvalue()
            fileinfo = {"name": uf.name, "ext": uf.name.split(".")[-1].lower(), "data": file_bytes}
            with st.spinner(f"ğŸ“– {fileinfo['name']} ë¶„ì„ ì¤‘..."):
                analysis_result = analyze_file(fileinfo)
            # ë¶„ì„ ê²°ê³¼ë¥¼ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€
            st.session_state.chat_messages.append({"role": "system", "content": f"ğŸ“„ {fileinfo['name']} ë¶„ì„ ì™„ë£Œ."})
            st.session_state.chat_messages.append({"role": "assistant", "content": analysis_result})
    
    # ì‚¬ìš©ì ì…ë ¥
    user_msg = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    if user_msg:
        st.session_state.chat_messages.append({"role": "user", "content": user_msg})
        with st.chat_message("user"):
            st.write(user_msg)
        
        # GPT í˜¸ì¶œ
        with st.spinner("GPT ì‘ë‹µ ì¤‘..."):
            gpt_response = ask_gpt(st.session_state.chat_messages)
        
        st.session_state.chat_messages.append({"role": "assistant", "content": gpt_response})
        with st.chat_message("assistant"):
            st.write(gpt_response)

###############################################################################
# ì»¤ë®¤ë‹ˆí‹° íƒ­
###############################################################################
def community_tab():
    st.header("ğŸŒ ì»¤ë®¤ë‹ˆí‹° (ë¬¸ì„œ ê³µìœ  ë° í† ë¡ )")
    st.info("""
        **[ì»¤ë®¤ë‹ˆí‹° ì‚¬ìš©ë²• ì•ˆë‚´]**
        1. ìƒë‹¨ì˜ ê²€ìƒ‰ì°½ì—ì„œ ì œëª© ë˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ê¸°ì¡´ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        2. 'ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±' ì˜ì—­ì—ì„œ ì œëª©, ë‚´ìš© ë° íŒŒì¼(PDF/PPTX/DOCX, ì´ë¯¸ì§€)ì„ ì²¨ë¶€í•˜ì—¬ ê²Œì‹œê¸€ì„ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        3. ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸° ì˜ì—­ì—ì„œ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ“ê¸€ ì‘ì„± ì‹œ ì„ì˜ì˜ 'ìœ ì €_ìˆ«ì'ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
        """)
    
    # ê²€ìƒ‰ ê¸°ëŠ¥
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ (ì œëª© ë˜ëŠ” ë‚´ìš© ì…ë ¥)")
    
    # ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ ì´ˆê¸°í™”
    if "community_posts" not in st.session_state:
        st.session_state.community_posts = []
    
    # ìƒˆ ê²Œì‹œê¸€ ì‘ì„±
    st.subheader("ğŸ“¤ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±")
    title = st.text_input("ì œëª©")
    content = st.text_area("ë‚´ìš©")
    uploaded_files = st.file_uploader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "pptx", "docx", "jpg", "png"], accept_multiple_files=True)
    
    if st.button("ê²Œì‹œê¸€ ë“±ë¡"):
        if title.strip() and content.strip():
            files_info = (
                [{"name": uf.name, "ext": uf.name.split(".")[-1].lower(), "data": uf.getvalue()} for uf in uploaded_files]
                if uploaded_files else []
            )
            new_post = {"title": title, "content": content, "files": files_info, "comments": []}
            st.session_state.community_posts.append(new_post)
            st.success("âœ… ê²Œì‹œê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ê²Œì‹œê¸€ ëª©ë¡ í‘œì‹œ
    st.subheader("ğŸ“œ ê²Œì‹œê¸€ ëª©ë¡")
    for idx, post in enumerate(st.session_state.community_posts):
        # ê²€ìƒ‰ì–´ í•„í„°
        if search_query.lower() in post["title"].lower() or search_query.lower() in post["content"].lower():
            with st.expander(f"{idx+1}. {post['title']}"):
                st.write(post["content"])
                
                # ëŒ“ê¸€ ì‘ì„±
                comment = st.text_input(f"ğŸ’¬ ëŒ“ê¸€ ì‘ì„± (ì‘ì„±ì: ìœ ì €_{random.randint(100,999)})", key=f"comment_{idx}")
                if st.button("ëŒ“ê¸€ ë“±ë¡", key=f"comment_btn_{idx}"):
                    post["comments"].append(f"ğŸ“ ìœ ì €_{random.randint(100,999)}: {comment}")
                
                # ëŒ“ê¸€ ëª©ë¡
                for c in post["comments"]:
                    st.write(c)

###############################################################################
# ë©”ì¸ ì‹¤í–‰
###############################################################################
def main():
    st.title("ğŸ“š StudyHelper")
    st.markdown("""
        ## StudyHelper ì‚¬ìš©ë²• ì•ˆë‚´
        - **GPT ì±„íŒ…:** íŒŒì¼ ì—…ë¡œë“œë¥¼ í†µí•´ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³ , ChatGPTì™€ ì‹¤ì‹œê°„ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - **ì»¤ë®¤ë‹ˆí‹°:** ê²Œì‹œê¸€ì„ ì‘ì„±í•˜ê³ , ë¬¸ì„œë¥¼ ê³µìœ í•˜ë©°, ëŒ“ê¸€ì„ í†µí•´ ì˜ê²¬ì„ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        **ì£¼ì˜ì‚¬í•­**
        - **ì €ì‘ê¶Œ ì•ˆë‚´:** ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ ë° ì½˜í…ì¸ ëŠ” ì €ì‘ê¶Œ ë³´í˜¸ ëŒ€ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
          ë³¸ í”Œë«í¼ì€ ì‚¬ìš©ìê°€ ì œê³µí•œ ìë£Œì— ëŒ€í•œ ì €ì‘ê¶Œ ì±…ì„ì„ ì§€ì§€ ì•Šìœ¼ë¯€ë¡œ, ìë£Œ ì—…ë¡œë“œ ì „ ê´€ë ¨ ë²•ê·œ ë° ì €ì‘ê¶Œ ì‚¬í•­ì„ ë°˜ë“œì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.
        - **ì¤‘ìš” ì •ë³´ í™•ì¸:** ChatGPTì˜ ë‹µë³€ì€ ì°¸ê³ ìš©ìœ¼ë¡œ ì œê³µë˜ë©°, ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•í•œ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
          ì¤‘ìš”í•œ ì •ë³´ë‚˜ ì˜ì‚¬ê²°ì •ì„ ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì¶”ê°€ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
        """)
    
    tab = st.sidebar.radio("ğŸ” ë©”ë‰´ ì„ íƒ", ("GPT ì±„íŒ…", "ì»¤ë®¤ë‹ˆí‹°"))
    if tab == "GPT ì±„íŒ…":
        gpt_chat_tab()
    else:
        community_tab()

if __name__ == "__main__":
    main()

import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv

# OpenAI ëª¨ë“ˆì´ ì—†ì–´ë„ Gemini APIë¡œ ëŒ€ì²´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

from pathlib import Path
import docx2txt
import pdfplumber
from pptx import Presentation
import random
import subprocess
import nltk
from nltk.corpus import stopwords
import google.generativeai as genai

###############################################################################
# NLTK ì„¤ì • (ë¶ˆìš©ì–´ ìë™ ë‹¤ìš´ë¡œë“œ)
###############################################################################
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

try:
    stopwords.words("english")
except LookupError:
    nltk.download("stopwords", download_dir=nltk_data_dir)

korean_stopwords = ["ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ë”"]
english_stopwords = set(stopwords.words("english"))
final_stopwords = english_stopwords.union(set(korean_stopwords))

###############################################################################
# í™˜ê²½ ë³€ìˆ˜ ë° API ì„¤ì •
###############################################################################
dotenv_path = Path(".env")
load_dotenv(dotenv_path=dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ Gemini API í‚¤ ê°€ì ¸ì˜¤ê¸°
USE_GEMINI_ALWAYS = os.getenv("USE_GEMINI_ALWAYS", "False").lower() == "true"  # Gemini APIë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í• ì§€ ì—¬ë¶€

# OpenAI APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ê±°ë‚˜ USE_GEMINI_ALWAYSê°€ Trueì¸ ê²½ìš° Gemini API ì‚¬ìš©
if USE_GEMINI_ALWAYS or not OPENAI_API_KEY or OpenAI is None:
    st.warning("ğŸš¨ OpenAI APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ Google Gemini APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    use_gemini_always = True
else:
    use_gemini_always = False
    client = OpenAI(api_key=OPENAI_API_KEY)

###############################################################################
# OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ (í•„ìš” ì‹œ)
###############################################################################
def migrate_openai_api():
    try:
        subprocess.run(["openai", "migrate"], capture_output=True, text=True, check=True)
        st.info("OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ. ì•± ì¬ì‹œì‘ í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"API ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        st.stop()

###############################################################################
# GPT API í˜¸ì¶œ í•¨ìˆ˜
###############################################################################
def ask_gpt(messages, model_name="gpt-4", temperature=0.7):
    """OpenAI GPT ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜. ì‹¤íŒ¨ ì‹œ Gemini APIë¡œ ì „í™˜."""
    if use_gemini_always:
        return ask_gemini(messages, temperature=temperature)
    try:
        resp = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=temperature,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        if "429" in str(e):
            st.error("ğŸš¨ OpenAI API ì¿¼í„°ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê³„ì •ì˜ ê²°ì œ ì •ë³´ì™€ í”Œëœì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            st.error(f"ğŸš¨ OpenAI API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ask_gemini(messages, temperature=temperature)

###############################################################################
# Google Gemini API í˜¸ì¶œ í•¨ìˆ˜ (ìµœì‹  ë°©ì‹)
###############################################################################
def ask_gemini(messages, temperature=0.7):
    """Gemini API í˜¸ì¶œ í•¨ìˆ˜. ìµœì‹  GenerativeModel ì‚¬ìš©."""
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')  # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        prompt = messages[-1]["content"] if messages else ""
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=temperature)
        )
        return response.text.strip()
    except Exception as e:
        st.error(f"ğŸš¨ Google Gemini API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ""

###############################################################################
# ë¬¸ì„œ ë¶„ì„ í•¨ìˆ˜
###############################################################################
def parse_docx(file_bytes):
    try:
        return docx2txt.process(BytesIO(file_bytes))
    except Exception:
        return "ğŸ“„ DOCX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_pdf(file_bytes):
    text_list = []
    try:
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text_list.append(page.extract_text() or "")
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PDF íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_ppt(file_bytes):
    text_list = []
    try:
        prs = Presentation(BytesIO(file_bytes))
        for slide in prs.slides:
            for shape in slide.shapes:
                if shape.has_text_frame:
                    text_list.append(shape.text)
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PPTX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def analyze_file(fileinfo):
    ext = fileinfo["ext"]
    data = fileinfo["data"]
    if ext == "docx":
        return parse_docx(data)
    elif ext == "pdf":
        return parse_pdf(data)
    elif ext == "pptx":
        return parse_ppt(data)
    else:
        return "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF, PPTX, DOCXë§Œ ì§€ì›í•©ë‹ˆë‹¤."

def merge_documents(file_list):
    merged_text = ""
    for file in file_list:
        file_bytes = file.getvalue()
        fileinfo = {
            "name": file.name,
            "ext": file.name.split(".")[-1].lower(),
            "data": file_bytes
        }
        text = analyze_file(fileinfo)
        merged_text += f"\n\n--- {file.name} ---\n\n" + text
    return merged_text

###############################################################################
# GPT ë¬¸ì„œ ë¶„ì„, ì§ˆë¬¸, ë§ì¶¤ë²• ìˆ˜ì • ê¸°ëŠ¥
###############################################################################
def gpt_document_review(text):
    summary_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    summary = ask_gpt(summary_prompt)
    question_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê²€í† í•˜ê³ , ì‚¬ìš©ìê°€ ìˆ˜ì •í•˜ê±°ë‚˜ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸ì„ 3ê°€ì§€ ì œì‹œí•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    questions = ask_gpt(question_prompt)
    correction_prompt = [
        {"role": "system", "content": "ì´ ë¬¸ì„œì—ì„œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •í•œ ë¶€ë¶„ì„ ê°•ì¡°í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    corrections = ask_gpt(correction_prompt)
    return summary, questions, corrections

###############################################################################
# GPT/AI ì±„íŒ… ë° ë¬¸ì„œ ë¶„ì„ íƒ­
###############################################################################
def gpt_chat_tab():
    st.info("""
**ì‚¬ìš©ë²•**
1. PDF/PPTX/DOCX íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
2. ë¬¸ì„œ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.
3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
4. ì•„ë˜ ì±„íŒ…ì°½ì—ì„œ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    uploaded_files = st.file_uploader(
        "ğŸ“ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/PPTX/DOCX ì§€ì›)",
        type=["pdf", "pptx", "docx"],
        accept_multiple_files=True
    )
    if uploaded_files is not None and len(uploaded_files) > 0:
        with st.spinner("ğŸ“– ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘..."):
            document_text = merge_documents(uploaded_files)
            summary, questions, corrections = gpt_document_review(document_text)
            st.session_state.document_text = document_text
            st.session_state.summary = summary
            st.session_state.questions = questions
            st.session_state.corrections = corrections
    elif "document_text" not in st.session_state:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œë©´ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    if "document_text" in st.session_state:
        st.subheader("ğŸ“Œ ë¬¸ì„œ ìš”ì•½")
        st.write(st.session_state.summary)
        st.subheader("ğŸ’¡ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸")
        st.write(st.session_state.questions)
        st.subheader("âœï¸ ë§ì¶¤ë²• ë° ë¬¸ì¥ ìˆ˜ì •")
        st.write(st.session_state.corrections)
    else:
        st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì£¼ì„¸ìš”.")
    st.warning("ì£¼ì˜: AI ëª¨ë¸ì€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.subheader("ğŸ’¬ AIì™€ ëŒ€í™”í•˜ê¸°")
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="chat_input")
    if st.button("ì „ì†¡"):
        if user_input.strip():
            if "document_text" in st.session_state:
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                chat_prompt = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©: " + st.session_state.document_text},
                    {"role": "user", "content": user_input}
                ]
                ai_response = ask_gpt(chat_prompt)
                st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
            else:
                st.error("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        else:
            st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            st.write(f"**ì‚¬ìš©ì**: {message['content']}")
        else:
            st.write(f"**AI**: {message['content']}")

###############################################################################
# ì»¤ë®¤ë‹ˆí‹° íƒ­
###############################################################################
def community_tab():
    st.header("ğŸŒ ì»¤ë®¤ë‹ˆí‹° (ë¬¸ì„œ ê³µìœ  ë° í† ë¡ )")
    st.info("""
    **[ì»¤ë®¤ë‹ˆí‹° ì‚¬ìš©ë²•]**
    1. ìƒë‹¨ì˜ ê²€ìƒ‰ì°½ì—ì„œ ì œëª© ë˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ê¸°ì¡´ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. 'ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±' ì˜ì—­ì—ì„œ ì œëª©, ë‚´ìš© ë° íŒŒì¼(PDF/PPTX/DOCX ì§€ì›)ì„ ì²¨ë¶€í•˜ì—¬ ê²Œì‹œê¸€ì„ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3. ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸° ì˜ì—­ì—ì„œ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ“ê¸€ ì‘ì„± ì‹œ ì„ì˜ì˜ 'ìœ ì €_ìˆ«ì'ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
    """)
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ (ì œëª© ë˜ëŠ” ë‚´ìš© ì…ë ¥)")
    if "community_posts" not in st.session_state:
        st.session_state.community_posts = []
    st.subheader("ğŸ“¤ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±")
    title = st.text_input("ì œëª©")
    content = st.text_area("ë‚´ìš©")
    uploaded_files = st.file_uploader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "pptx", "docx"], accept_multiple_files=True)
    if st.button("âœ… ê²Œì‹œê¸€ ë“±ë¡"):
        if title.strip() and content.strip():
            files_info = []
            if uploaded_files:
                for uf in uploaded_files:
                    file_bytes = uf.getvalue()
                    ext = uf.name.split(".")[-1].lower()
                    files_info.append({"name": uf.name, "ext": ext, "data": file_bytes})
            new_post = {"title": title, "content": content, "files": files_info, "comments": []}
            st.session_state.community_posts.append(new_post)
            st.success("âœ… ê²Œì‹œê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("ì œëª©ê³¼ ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.subheader("ğŸ“œ ê²Œì‹œê¸€ ëª©ë¡")
    for idx, post in enumerate(st.session_state.community_posts):
        if not search_query or search_query.lower() in post["title"].lower() or search_query.lower() in post["content"].lower():
            with st.expander(f"{idx+1}. {post['title']}"):
                st.write(post["content"])
                comment = st.text_input(f"ğŸ’¬ ëŒ“ê¸€ ì‘ì„± (ì‘ì„±ì: ìœ ì €_{random.randint(100,999)})", key=f"comment_{idx}")
                if st.button("ëŒ“ê¸€ ë“±ë¡", key=f"comment_btn_{idx}"):
                    if comment.strip():
                        post["comments"].append(f"ğŸ“ ìœ ì €_{random.randint(100,999)}: {comment}")
                    else:
                        st.error("ëŒ“ê¸€ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                for c in post["comments"]:
                    st.write(c)

###############################################################################
# Gemini ì´ë¯¸ì§€ ì˜ˆì œ (Mac í™˜ê²½ìš©)
###############################################################################
def gemini_image_demo():
    st.header("ğŸ–¼ï¸ Gemini ì´ë¯¸ì§€ ì˜ˆì œ")
    st.info("ì´ ì˜ˆì œëŠ” Mac í™˜ê²½ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ 2ê°œì™€ URLì˜ ì´ë¯¸ì§€ë¥¼ Gemini APIë¡œ ì „ì†¡í•˜ì—¬ 'What do these images have in common?' ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.")
    image_path_1 = "/Users/yourusername/path/to/your/image1.jpeg"  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    image_path_2 = "/Users/yourusername/path/to/your/image2.jpeg"  # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    image_url_1 = "https://goo.gle/instrument-img"                # ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ì˜ URL
    try:
        import PIL.Image
        pil_image = PIL.Image.open(image_path_1)
        image_info_1 = f"Image1 size: {pil_image.size}"
    except Exception as e:
        image_info_1 = f"Image1 load error: {e}"
    try:
        pil_image = PIL.Image.open(image_path_2)
        image_info_2 = f"Image2 size: {pil_image.size}"
    except Exception as e:
        image_info_2 = f"Image2 load error: {e}"
    try:
        import requests
        downloaded_image = requests.get(image_url_1)
        image_info_3 = f"Image3 downloaded: {len(downloaded_image.content)} bytes"
    except Exception as e:
        image_info_3 = f"Image3 download error: {e}"
    prompt = f"What do these images have in common?\n{image_info_1}\n{image_info_2}\n{image_info_3}"
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.7)
        )
        st.write(response.text)
    except Exception as e:
        st.error(f"ğŸš¨ Google Gemini API í˜¸ì¶œ ì—ëŸ¬: {e}")

###############################################################################
# ë©”ì¸ ì‹¤í–‰
###############################################################################
def main():
    st.title("ğŸ“š ThinkHelper - ìƒê°ë„ìš°ë¯¸")
    st.markdown("""
    **ì´ ì•±ì€ íŒŒì¼ ì—…ë¡œë“œì™€ AI ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**
    
    - **GPT ë¬¸ì„œ ë¶„ì„ íƒ­:**  
      1. PDF/PPTX/DOCX íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.  
      2. ë¬¸ì„œ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.  
      3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    - **ì»¤ë®¤ë‹ˆí‹° íƒ­:**  
      ê²Œì‹œê¸€ ë“±ë¡, ê²€ìƒ‰, ëŒ“ê¸€ ê¸°ëŠ¥ì„ í†µí•´ ë¬¸ì„œë¥¼ ê³µìœ í•˜ê³  í† ë¡ í•©ë‹ˆë‹¤.
    - **Gemini ì´ë¯¸ì§€ ì˜ˆì œ:**  
      ì¶”ê°€ëœ Gemini ì´ë¯¸ì§€ ì˜ˆì œ ì½”ë“œë¥¼ í†µí•´ ì´ë¯¸ì§€ ë¶„ì„ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """)
    tab = st.sidebar.radio("ğŸ” ë©”ë‰´ ì„ íƒ", ("GPT ë¬¸ì„œ ë¶„ì„", "ì»¤ë®¤ë‹ˆí‹°", "Gemini ì´ë¯¸ì§€ ì˜ˆì œ"))
    if tab == "GPT ë¬¸ì„œ ë¶„ì„":
        gpt_chat_tab()
    elif tab == "ì»¤ë®¤ë‹ˆí‹°":
        community_tab()
    else:
        gemini_image_demo()

if __name__ == "__main__":
    main()

###############################################################################
# ì €ì‘ê¶Œ ì£¼ì˜ ë¬¸êµ¬
###############################################################################
st.markdown("""
---
**ì €ì‘ê¶Œ ì£¼ì˜ ë¬¸êµ¬**

- **ì½”ë“œ ì‚¬ìš©**: ì´ ì†ŒìŠ¤ ì½”ë“œëŠ” ì €ì‘ê¶Œë²•ì— ì˜í•´ ë³´í˜¸ë©ë‹ˆë‹¤. ë¬´ë‹¨ ë³µì œ, ë°°í¬, ìˆ˜ì • ë˜ëŠ” ìƒì—…ì  ì‚¬ìš©ì€ ê¸ˆì§€ë©ë‹ˆë‹¤. ê°œì¸ì , ë¹„ìƒì—…ì  ìš©ë„ë¡œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš© ì‹œ ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œê¸°í•´ì•¼ í•©ë‹ˆë‹¤.
- **íŒŒì¼ ì—…ë¡œë“œ**: ì‚¬ìš©ìëŠ” íŒŒì¼ì„ ì—…ë¡œë“œí•  ë•Œ ì €ì‘ê¶Œì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì €ì‘ê¶Œ ì¹¨í•´ ë¬¸ì œê°€ ë°œìƒí•  ê²½ìš°, ë³¸ ì„œë¹„ìŠ¤ëŠ” ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚
""")

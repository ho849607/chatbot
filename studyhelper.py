import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
# OpenAI í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ë„ Gemini APIë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
try:
    from openai import OpenAI  # OpenAI í´ë˜ìŠ¤ import
except ImportError:
    OpenAI = None
from pathlib import Path
import docx2txt
import pdfplumber
from pptx import Presentation
import random
import subprocess

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

###############################################################################
# NLTK ì„¤ì • (ë¶ˆìš©ì–´ ìë™ ë‹¤ìš´ë¡œë“œ)
###############################################################################
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

try:
    stopwords.words("english")
except LookupError:
    nltk.download("stopwords", download_dir=nltk_data_dir)

korean_stopwords = ["ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ë”"]
english_stopwords = set(stopwords.words("english"))
final_stopwords = english_stopwords.union(set(korean_stopwords))

###############################################################################
# í™˜ê²½ ë³€ìˆ˜ & API ì„¤ì •
###############################################################################
dotenv_path = Path(".env")
load_dotenv(dotenv_path=dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# OpenAI API í‚¤ê°€ ì—†ê±°ë‚˜ OpenAI ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•œ ê²½ìš° Gemini APIë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
if not OPENAI_API_KEY or OpenAI is None:
    st.warning("ğŸš¨ OpenAI API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ Google Gemini APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    use_gemini_always = True
else:
    use_gemini_always = False
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = OpenAI(api_key=OPENAI_API_KEY)

###############################################################################
# OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ (ì˜ˆì „ ë²„ì „ í˜¸í™˜ - í•„ìš” ì‹œ)
###############################################################################
def migrate_openai_api():
    try:
        subprocess.run(["openai", "migrate"], capture_output=True, text=True, check=True)
        st.info("OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ. ì•± ì¬ì‹œì‘ í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"API ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        st.stop()

###############################################################################
# GPT API í˜¸ì¶œ í•¨ìˆ˜ (ë¬¸ì„œ ë¶„ì„ & ì§ˆë¬¸ & ë§ì¶¤ë²• ìˆ˜ì •)
###############################################################################
def ask_gpt(messages, model_name="gpt-4", temperature=0.7):
    """OpenAIì˜ GPT ëª¨ë¸ê³¼ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜. ë§Œì•½ í˜¸ì¶œì— ì‹¤íŒ¨í•˜ê±°ë‚˜ API í‚¤ê°€ ì—†ìœ¼ë©´ Google Gemini APIë¡œ fallback."""
    if use_gemini_always:
        return ask_gemini(messages, model_name="gemini", temperature=temperature)
    try:
        resp = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=temperature,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"ğŸš¨ OpenAI API í˜¸ì¶œ ì—ëŸ¬: {e}. Google Gemini APIë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        return ask_gemini(messages, model_name="gemini", temperature=temperature)

###############################################################################
# Google Gemini API í˜¸ì¶œ í•¨ìˆ˜ (ì˜ˆì‹œ)
###############################################################################
def ask_gemini(messages, model_name="gemini", temperature=0.7):
    """
    Google Gemini API í˜¸ì¶œ í•¨ìˆ˜ (ì‹¤ì œ êµ¬í˜„ì€ Gemini API ë¬¸ì„œì— ë”°ë¼ ìˆ˜ì •)
    í˜„ì¬ëŠ” ì˜ˆì‹œìš© placeholder í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        # ì‹¤ì œ Gemini API í˜¸ì¶œ ì½”ë“œë¥¼ ì´ê³³ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        # ì˜ˆì‹œ:
        # response = gemini_client.chat.completions.create(
        #     model=model_name,
        #     messages=messages,
        #     temperature=temperature,
        # )
        # return response.choices[0].message.content.strip()
        return "Google Gemini API ì‘ë‹µ ì˜ˆì‹œ: ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ ê¸°ëŠ¥ì…ë‹ˆë‹¤."
    except Exception as e:
        st.error(f"ğŸš¨ Google Gemini API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ""

###############################################################################
# ë¬¸ì„œ ë¶„ì„ í•¨ìˆ˜ (PDF, PPTX, DOCX)
###############################################################################
def parse_docx(file_bytes):
    """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        return docx2txt.process(BytesIO(file_bytes))
    except Exception:
        return "ğŸ“„ DOCX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_pdf(file_bytes):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    text_list = []
    try:
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text_list.append(page.extract_text() or "")
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PDF íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_ppt(file_bytes):
    """PPTX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    text_list = []
    try:
        prs = Presentation(BytesIO(file_bytes))
        for slide in prs.slides:
            for shape in slide.shapes:
                if shape.has_text_frame:
                    text_list.append(shape.text)
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PPTX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def analyze_file(fileinfo):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¶„ì„"""
    ext = fileinfo["ext"]
    data = fileinfo["data"]
    if ext == "docx":
        return parse_docx(data)
    elif ext == "pdf":
        return parse_pdf(data)
    elif ext == "pptx":
        return parse_ppt(data)
    else:
        return "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."

###############################################################################
# GPT ë¬¸ì„œ ë¶„ì„ & ì§ˆë¬¸ & ìˆ˜ì • ê¸°ëŠ¥
###############################################################################
def gpt_document_review(text):
    """GPTê°€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½, ì§ˆë¬¸ ë° ìˆ˜ì •"""
    # 1. ë¬¸ì„œ ìš”ì•½ ìš”ì²­
    summary_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    summary = ask_gpt(summary_prompt)

    # 2. ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
    question_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê²€í† í•˜ê³ , ì‚¬ìš©ìê°€ ìˆ˜ì •í•˜ê±°ë‚˜ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸ì„ 3ê°€ì§€ ì œì‹œí•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    questions = ask_gpt(question_prompt)

    # 3. ë§ì¶¤ë²• ë° ë¬¸ì¥ ìˆ˜ì • ìš”ì²­
    correction_prompt = [
        {"role": "system", "content": "ì´ ë¬¸ì„œì—ì„œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •í•œ ë¶€ë¶„ì„ ê°•ì¡°í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    corrections = ask_gpt(correction_prompt)

    return summary, questions, corrections

###############################################################################
# GPT/AI ì±„íŒ… + ë¬¸ì„œ ë¶„ì„ íƒ­
###############################################################################
def gpt_chat_tab():
    # ì‚¬ìš©ë²• ì•ˆë‚´
    st.info("""
**ì‚¬ìš©ë²•**

1. PDF/PPTX/DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
2. ë¬¸ì„œì˜ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.
3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
4. ì•„ë˜ ì±„íŒ…ì°½ì—ì„œ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    # AI ëª¨ë¸ ì„ íƒ (ChatGPT ë˜ëŠ” Google Gemini)
    ai_provider = st.radio("ì‚¬ìš©í•  AI ëª¨ë¸ ì„ íƒ", ("ChatGPT", "Google Gemini"), index=0)
    
    # ì„¸ì…˜ ìƒíƒœì— ì±„íŒ… ê¸°ë¡ ì €ì¥
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ë° ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥ (í•œ ë²ˆ ë¶„ì„ í›„ ì¬ì‚¬ìš©)
    uploaded_file = st.file_uploader(
        "ğŸ“ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/PPTX/DOCX ì§€ì›)",
        type=["pdf", "pptx", "docx"],
        accept_multiple_files=False
    )
    
    # íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆê±°ë‚˜ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¶„ì„ ì‹¤í–‰
    if uploaded_file is not None or "document_text" not in st.session_state:
        if uploaded_file is not None:
            file_bytes = uploaded_file.getvalue()
            fileinfo = {
                "name": uploaded_file.name,
                "ext": uploaded_file.name.split(".")[-1].lower(),
                "data": file_bytes
            }
            with st.spinner(f"ğŸ“– {fileinfo['name']} ë¶„ì„ ì¤‘..."):
                document_text = analyze_file(fileinfo)
                # GPT ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰
                summary, questions, corrections = gpt_document_review(document_text)
                # ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.document_text = document_text
                st.session_state.summary = summary
                st.session_state.questions = questions
                st.session_state.corrections = corrections
        else:
            st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œë©´ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # ë¶„ì„ ê²°ê³¼ê°€ ì„¸ì…˜ì— ìˆìœ¼ë©´ í‘œì‹œ
    if "document_text" in st.session_state:
        st.subheader("ğŸ“Œ ë¬¸ì„œ ìš”ì•½")
        st.write(st.session_state.summary)
        st.subheader("ğŸ’¡ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸")
        st.write(st.session_state.questions)
        st.subheader("âœï¸ ë§ì¶¤ë²• ë° ë¬¸ì¥ ìˆ˜ì •")
        st.write(st.session_state.corrections)
    else:
        st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì£¼ì„¸ìš”.")
    
    st.warning("ì£¼ì˜: AI ëª¨ë¸ì€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # ì±„íŒ…ì°½ ì¶”ê°€
    st.subheader("ğŸ’¬ AIì™€ ëŒ€í™”í•˜ê¸°")
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="chat_input")
    if st.button("ì „ì†¡"):
        if user_input.strip() and "document_text" in st.session_state:
            # ì‚¬ìš©ì ì…ë ¥ì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            # ì„¸ì…˜ì— ì €ì¥ëœ ë¬¸ì„œ ë‚´ìš©ì„ í™œìš©í•˜ì—¬ ì±„íŒ… í”„ë¡¬í”„íŠ¸ ìƒì„±
            chat_prompt = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©: " + st.session_state.document_text},
                {"role": "user", "content": user_input}
            ]
            # ì„ íƒí•œ AI ëª¨ë¸ì— ë”°ë¼ í˜¸ì¶œ (ëª¨ë¸ ì„ íƒê³¼ ë³„ê°œë¡œ, OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ fallbackë„ ì ìš©ë©ë‹ˆë‹¤.)
            if ai_provider == "ChatGPT":
                ai_response = ask_gpt(chat_prompt)
            else:
                ai_response = ask_gemini(chat_prompt)
            # AI ì‘ë‹µì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
            st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
        elif "document_text" not in st.session_state:
            st.error("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            st.write(f"**ì‚¬ìš©ì**: {message['content']}")
        else:
            st.write(f"**AI**: {message['content']}")

###############################################################################
# ì»¤ë®¤ë‹ˆí‹° íƒ­
###############################################################################
def community_tab():
    st.header("ğŸŒ ì»¤ë®¤ë‹ˆí‹° (ë¬¸ì„œ ê³µìœ  ë° í† ë¡ )")
    st.info("""
    **[ì»¤ë®¤ë‹ˆí‹° ì‚¬ìš©ë²•]**
    1. ìƒë‹¨ì˜ ê²€ìƒ‰ì°½ì—ì„œ ì œëª© ë˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ê¸°ì¡´ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. 'ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±' ì˜ì—­ì—ì„œ ì œëª©, ë‚´ìš© ë° íŒŒì¼(PDF/PPTX/DOCX ì§€ì›)ì„ ì²¨ë¶€í•˜ì—¬ ê²Œì‹œê¸€ì„ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3. ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸° ì˜ì—­ì—ì„œ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ“ê¸€ ì‘ì„± ì‹œ ì„ì˜ì˜ 'ìœ ì €_ìˆ«ì'ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
    """)
    
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ (ì œëª© ë˜ëŠ” ë‚´ìš© ì…ë ¥)")

    if "community_posts" not in st.session_state:
        st.session_state.community_posts = []

    st.subheader("ğŸ“¤ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±")
    title = st.text_input("ì œëª©")
    content = st.text_area("ë‚´ìš©")
    uploaded_files = st.file_uploader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "pptx", "docx"], accept_multiple_files=True)

    if st.button("âœ… ê²Œì‹œê¸€ ë“±ë¡"):
        if title.strip() and content.strip():
            files_info = []
            if uploaded_files:
                for uf in uploaded_files:
                    file_bytes = uf.getvalue()
                    ext = uf.name.split(".")[-1].lower()
                    files_info.append({"name": uf.name, "ext": ext, "data": file_bytes})
            new_post = {"title": title, "content": content, "files": files_info, "comments": []}
            st.session_state.community_posts.append(new_post)
            st.success("âœ… ê²Œì‹œê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

    st.subheader("ğŸ“œ ê²Œì‹œê¸€ ëª©ë¡")
    for idx, post in enumerate(st.session_state.community_posts):
        if search_query.lower() in post["title"].lower() or search_query.lower() in post["content"].lower():
            with st.expander(f"{idx+1}. {post['title']}"):
                st.write(post["content"])
                comment = st.text_input(f"ğŸ’¬ ëŒ“ê¸€ ì‘ì„± (ì‘ì„±ì: ìœ ì €_{random.randint(100,999)})", key=f"comment_{idx}")
                if st.button("ëŒ“ê¸€ ë“±ë¡", key=f"comment_btn_{idx}"):
                    post["comments"].append(f"ğŸ“ ìœ ì €_{random.randint(100,999)}: {comment}")
                for c in post["comments"]:
                    st.write(c)

###############################################################################
# ë©”ì¸ ì‹¤í–‰
###############################################################################
def main():
    st.title("ğŸ“š ThinHelper - ìƒê°ë„ìš°ë¯¸")

    st.markdown("""
    **ì´ ì•±ì€ íŒŒì¼ ì—…ë¡œë“œì™€ AI ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**
    
    - **GPT ë¬¸ì„œ ë¶„ì„ íƒ­:**  
      1. PDF/PPTX/DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.  
      2. ë¬¸ì„œ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.  
      3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    - **ì»¤ë®¤ë‹ˆí‹° íƒ­:**  
      ê²Œì‹œê¸€ ë“±ë¡, ê²€ìƒ‰, ëŒ“ê¸€ ê¸°ëŠ¥ì„ í†µí•´ ë¬¸ì„œë¥¼ ê³µìœ í•˜ê³  í† ë¡ í•©ë‹ˆë‹¤.
    """)

    tab = st.sidebar.radio("ğŸ” ë©”ë‰´ ì„ íƒ", ("GPT ë¬¸ì„œ ë¶„ì„", "ì»¤ë®¤ë‹ˆí‹°"))
    if tab == "GPT ë¬¸ì„œ ë¶„ì„":
        gpt_chat_tab()
    else:
        community_tab()

if __name__ == "__main__":
    main()

###############################################################################
# ì €ì‘ê¶Œ ì£¼ì˜ ë¬¸êµ¬ (Copyright Notice)
###############################################################################
"""
íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì €ì‘ê¶Œì— ìœ ì˜í•´ì•¼ í•˜ë©°, ìš°ë¦¬ëŠ” ì´ ì½”ë“œì˜ ì‚¬ìš© ë˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì–´ë– í•œ ì†í•´, ì˜¤ìš©, ì €ì‘ê¶Œ ì¹¨í•´ ë¬¸ì œì— ëŒ€í•´ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.

This source code is protected by copyright law. Unauthorized reproduction, distribution, modification, or commercial use is prohibited. 
It may only be used for personal, non-commercial purposes, and the source must be clearly credited upon use. 
Users must be mindful of copyright when uploading files, and we are not responsible for any damages, misuse, or copyright infringement issues arising from the use of this code or uploaded files.
"""

import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
# OpenAI í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ë„ Gemini APIë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
try:
    from openai import OpenAI  # OpenAI í´ë˜ìŠ¤ import
except ImportError:
    OpenAI = None
from pathlib import Path
import docx2txt
import pdfplumber
from pptx import Presentation
import random
import subprocess

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

# Google Generative AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ìˆ˜ì •ëœ ë°©ì‹)
import google.generativeai as genai
from google.generativeai import types

import pathlib
import PIL.Image
import requests

###############################################################################
# NLTK ì„¤ì • (ë¶ˆìš©ì–´ ìë™ ë‹¤ìš´ë¡œë“œ)
###############################################################################
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

try:
    stopwords.words("english")
except LookupError:
    nltk.download("stopwords", download_dir=nltk_data_dir)

korean_stopwords = ["ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ë”"]
english_stopwords = set(stopwords.words("english"))
final_stopwords = english_stopwords.union(set(korean_stopwords))

###############################################################################
# í™˜ê²½ ë³€ìˆ˜ ë° API ì„¤ì •
###############################################################################
dotenv_path = Path(".env")
load_dotenv(dotenv_path=dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# OpenAI API í‚¤ê°€ ì—†ê±°ë‚˜ OpenAI ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìœ¼ë©´ Gemini APIë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
if not OPENAI_API_KEY or OpenAI is None:
    st.warning("ğŸš¨ OpenAI API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ Google Gemini APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    use_gemini_always = True
else:
    use_gemini_always = False
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = OpenAI(api_key=OPENAI_API_KEY)

###############################################################################
# OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ (í•„ìš” ì‹œ)
###############################################################################
def migrate_openai_api():
    try:
        subprocess.run(["openai", "migrate"], capture_output=True, text=True, check=True)
        st.info("OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ. ì•± ì¬ì‹œì‘ í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"API ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        st.stop()

###############################################################################
# GPT API í˜¸ì¶œ í•¨ìˆ˜ (ë¬¸ì„œ ë¶„ì„, ì§ˆë¬¸, ë§ì¶¤ë²• ìˆ˜ì •)
###############################################################################
def ask_gpt(messages, model_name="gpt-4", temperature=0.7):
    """OpenAIì˜ GPT ëª¨ë¸ê³¼ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜. í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ Gemini APIë¡œ fallback."""
    if use_gemini_always:
        return ask_gemini(messages, model_name="gemini", temperature=temperature)
    try:
        resp = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=temperature,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"ğŸš¨ OpenAI API í˜¸ì¶œ ì—ëŸ¬: {e}. Google Gemini APIë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        return ask_gemini(messages, model_name="gemini", temperature=temperature)

###############################################################################
# Google Gemini API í˜¸ì¶œ í•¨ìˆ˜ (ìˆ˜ì •ëœ ë°©ì‹)
###############################################################################
def ask_gemini(messages, model_name="gemini", temperature=0.7):
    """
    Gemini API í˜¸ì¶œ í•¨ìˆ˜  
    API í‚¤ë¥¼ ì„¤ì •í•œ í›„ ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ í•˜ì—¬ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # API í‚¤ ì„¤ì • (ì‹¤ì œ API í‚¤ë¡œ ë³€ê²½)
        genai.configure(api_key="GEMINI_API_KEY")
        prompt = messages[-1]["content"] if messages else ""
        response = genai.generate_text(
            model="gemini-2.0-flash",  # ëª¨ë¸ ì´ë¦„ì€ í•„ìš”ì— ë”°ë¼ ë³€ê²½í•˜ì„¸ìš”.
            prompt=prompt,
            temperature=temperature
        )
        return response.result.strip()
    except Exception as e:
        st.error(f"ğŸš¨ Google Gemini API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ""

###############################################################################
# ë¬¸ì„œ ë¶„ì„ í•¨ìˆ˜ (PDF, PPTX, DOCX)
###############################################################################
def parse_docx(file_bytes):
    try:
        return docx2txt.process(BytesIO(file_bytes))
    except Exception:
        return "ğŸ“„ DOCX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_pdf(file_bytes):
    text_list = []
    try:
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text_list.append(page.extract_text() or "")
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PDF íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_ppt(file_bytes):
    text_list = []
    try:
        prs = Presentation(BytesIO(file_bytes))
        for slide in prs.slides:
            for shape in slide.shapes:
                if shape.has_text_frame:
                    text_list.append(shape.text)
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PPTX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def analyze_file(fileinfo):
    ext = fileinfo["ext"]
    data = fileinfo["data"]
    if ext == "docx":
        return parse_docx(data)
    elif ext == "pdf":
        return parse_pdf(data)
    elif ext == "pptx":
        return parse_ppt(data)
    else:
        return "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."

def merge_documents(file_list):
    merged_text = ""
    for file in file_list:
        file_bytes = file.getvalue()
        fileinfo = {
            "name": file.name,
            "ext": file.name.split(".")[-1].lower(),
            "data": file_bytes
        }
        text = analyze_file(fileinfo)
        merged_text += f"\n\n--- {file.name} ---\n\n" + text
    return merged_text

###############################################################################
# GPT ë¬¸ì„œ ë¶„ì„, ì§ˆë¬¸, ë§ì¶¤ë²• ìˆ˜ì • ê¸°ëŠ¥
###############################################################################
def gpt_document_review(text):
    summary_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    summary = ask_gpt(summary_prompt)
    question_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê²€í† í•˜ê³ , ì‚¬ìš©ìê°€ ìˆ˜ì •í•˜ê±°ë‚˜ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸ì„ 3ê°€ì§€ ì œì‹œí•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    questions = ask_gpt(question_prompt)
    correction_prompt = [
        {"role": "system", "content": "ì´ ë¬¸ì„œì—ì„œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •í•œ ë¶€ë¶„ì„ ê°•ì¡°í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    corrections = ask_gpt(correction_prompt)
    return summary, questions, corrections

###############################################################################
# GPT/AI ì±„íŒ… ë° ë¬¸ì„œ ë¶„ì„ íƒ­
###############################################################################
def gpt_chat_tab():
    st.info("""
**ì‚¬ìš©ë²•**
1. PDF/PPTX/DOCX íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
2. ë¬¸ì„œ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.
3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
4. ì•„ë˜ ì±„íŒ…ì°½ì—ì„œ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    uploaded_files = st.file_uploader(
        "ğŸ“ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/PPTX/DOCX ì§€ì›)",
        type=["pdf", "pptx", "docx"],
        accept_multiple_files=True
    )
    if uploaded_files is not None and len(uploaded_files) > 0:
        with st.spinner("ğŸ“– ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘..."):
            document_text = merge_documents(uploaded_files)
            summary, questions, corrections = gpt_document_review(document_text)
            st.session_state.document_text = document_text
            st.session_state.summary = summary
            st.session_state.questions = questions
            st.session_state.corrections = corrections
    elif "document_text" not in st.session_state:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œë©´ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    if "document_text" in st.session_state:
        st.subheader("ğŸ“Œ ë¬¸ì„œ ìš”ì•½")
        st.write(st.session_state.summary)
        st.subheader("ğŸ’¡ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸")
        st.write(st.session_state.questions)
        st.subheader("âœï¸ ë§ì¶¤ë²• ë° ë¬¸ì¥ ìˆ˜ì •")
        st.write(st.session_state.corrections)
    else:
        st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì£¼ì„¸ìš”.")
    st.warning("ì£¼ì˜: AI ëª¨ë¸ì€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.subheader("ğŸ’¬ AIì™€ ëŒ€í™”í•˜ê¸°")
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="chat_input")
    if st.button("ì „ì†¡"):
        if user_input.strip() and "document_text" in st.session_state:
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            chat_prompt = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©: " + st.session_state.document_text},
                {"role": "user", "content": user_input}
            ]
            ai_response = ask_gpt(chat_prompt)
            st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
        elif "document_text" not in st.session_state:
            st.error("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            st.write(f"**ì‚¬ìš©ì**: {message['content']}")
        else:
            st.write(f"**AI**: {message['content']}")

###############################################################################
# ì»¤ë®¤ë‹ˆí‹° íƒ­
###############################################################################
def community_tab():
    st.header("ğŸŒ ì»¤ë®¤ë‹ˆí‹° (ë¬¸ì„œ ê³µìœ  ë° í† ë¡ )")
    st.info("""
    **[ì»¤ë®¤ë‹ˆí‹° ì‚¬ìš©ë²•]**
    1. ìƒë‹¨ì˜ ê²€ìƒ‰ì°½ì—ì„œ ì œëª© ë˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ê¸°ì¡´ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. 'ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±' ì˜ì—­ì—ì„œ ì œëª©, ë‚´ìš© ë° íŒŒì¼(PDF/PPTX/DOCX ì§€ì›)ì„ ì²¨ë¶€í•˜ì—¬ ê²Œì‹œê¸€ì„ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3. ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸° ì˜ì—­ì—ì„œ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ“ê¸€ ì‘ì„± ì‹œ ì„ì˜ì˜ 'ìœ ì €_ìˆ«ì'ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
    """)
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ (ì œëª© ë˜ëŠ” ë‚´ìš© ì…ë ¥)")
    if "community_posts" not in st.session_state:
        st.session_state.community_posts = []
    st.subheader("ğŸ“¤ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±")
    title = st.text_input("ì œëª©")
    content = st.text_area("ë‚´ìš©")
    uploaded_files = st.file_uploader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "pptx", "docx"], accept_multiple_files=True)
    if st.button("âœ… ê²Œì‹œê¸€ ë“±ë¡"):
        if title.strip() and content.strip():
            files_info = []
            if uploaded_files:
                for uf in uploaded_files:
                    file_bytes = uf.getvalue()
                    ext = uf.name.split(".")[-1].lower()
                    files_info.append({"name": uf.name, "ext": ext, "data": file_bytes})
            new_post = {"title": title, "content": content, "files": files_info, "comments": []}
            st.session_state.community_posts.append(new_post)
            st.success("âœ… ê²Œì‹œê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
    st.subheader("ğŸ“œ ê²Œì‹œê¸€ ëª©ë¡")
    for idx, post in enumerate(st.session_state.community_posts):
        if search_query.lower() in post["title"].lower() or search_query.lower() in post["content"].lower():
            with st.expander(f"{idx+1}. {post['title']}"):
                st.write(post["content"])
                comment = st.text_input(f"ğŸ’¬ ëŒ“ê¸€ ì‘ì„± (ì‘ì„±ì: ìœ ì €_{random.randint(100,999)})", key=f"comment_{idx}")
                if st.button("ëŒ“ê¸€ ë“±ë¡", key=f"comment_btn_{idx}"):
                    post["comments"].append(f"ğŸ“ ìœ ì €_{random.randint(100,999)}: {comment}")
                for c in post["comments"]:
                    st.write(c)

###############################################################################
# Gemini ì´ë¯¸ì§€ ì˜ˆì œ (Mac í™˜ê²½ìš©)
###############################################################################
def gemini_image_demo():
    """
    Mac í™˜ê²½ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ 2ê°œì™€ URLì˜ ì´ë¯¸ì§€ë¥¼ Gemini APIë¡œ ì „ì†¡í•˜ì—¬,
    'What do these images have in common?' ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ì¶œë ¥í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.
    (ì°¸ê³ : í˜„ì¬ google-generativeaiëŠ” ì´ë¯¸ì§€ ì…ë ¥ì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì´ë¯¸ì§€ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•©ë‹ˆë‹¤.)
    """
    image_path_1 = "/Users/yourusername/path/to/your/image1.jpeg"  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    image_path_2 = "/Users/yourusername/path/to/your/image2.jpeg"  # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    image_url_1 = "https://goo.gle/instrument-img"                # ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ì˜ URL
    try:
        pil_image = PIL.Image.open(image_path_1)
        image_info_1 = f"Image1 size: {pil_image.size}"
    except Exception as e:
        image_info_1 = f"Image1 load error: {e}"
    try:
        b64_image = types.Part.from_bytes(
            data=pathlib.Path(image_path_2).read_bytes(),
            mime_type="image/jpeg"
        )
        image_info_2 = "Image2 loaded successfully as bytes."
    except Exception as e:
        image_info_2 = f"Image2 load error: {e}"
    try:
        downloaded_image = requests.get(image_url_1)
        image_info_3 = f"Image3 downloaded: {len(downloaded_image.content)} bytes"
    except Exception as e:
        image_info_3 = f"Image3 download error: {e}"
    prompt = f"What do these images have in common?\n{image_info_1}\n{image_info_2}\n{image_info_3}"
    try:
        genai.configure(api_key="GEMINI_API_KEY")
        response = genai.generate_text(
            model="gemini-2.0-flash-exp",
            prompt=prompt,
            temperature=0.7
        )
        print(response.result)
    except Exception as e:
        print(f"ğŸš¨ Google Gemini API í˜¸ì¶œ ì—ëŸ¬: {e}")

###############################################################################
# ë©”ì¸ ì‹¤í–‰
###############################################################################
def main():
    st.title("ğŸ“š ThinkHelper - ìƒê°ë„ìš°ë¯¸")
    st.markdown("""
    **ì´ ì•±ì€ íŒŒì¼ ì—…ë¡œë“œì™€ AI ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**
    
    - **GPT ë¬¸ì„œ ë¶„ì„ íƒ­:**  
      1. PDF/PPTX/DOCX íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.  
      2. ë¬¸ì„œ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.  
      3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    - **ì»¤ë®¤ë‹ˆí‹° íƒ­:**  
      ê²Œì‹œê¸€ ë“±ë¡, ê²€ìƒ‰, ëŒ“ê¸€ ê¸°ëŠ¥ì„ í†µí•´ ë¬¸ì„œë¥¼ ê³µìœ í•˜ê³  í† ë¡ í•©ë‹ˆë‹¤.
    - **Gemini ì´ë¯¸ì§€ ì˜ˆì œ:**  
      ì¶”ê°€ëœ Gemini ì´ë¯¸ì§€ ì˜ˆì œ ì½”ë“œë¥¼ í†µí•´ ì´ë¯¸ì§€ ë¶„ì„ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """)
    tab = st.sidebar.radio("ğŸ” ë©”ë‰´ ì„ íƒ", ("GPT ë¬¸ì„œ ë¶„ì„", "ì»¤ë®¤ë‹ˆí‹°", "Gemini ì´ë¯¸ì§€ ì˜ˆì œ"))
    if tab == "GPT ë¬¸ì„œ ë¶„ì„":
        gpt_chat_tab()
    elif tab == "ì»¤ë®¤ë‹ˆí‹°":
        community_tab()
    else:
        st.info("Gemini ì´ë¯¸ì§€ ì˜ˆì œ ì‹¤í–‰ ì¤‘ (ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”).")
        gemini_image_demo()

if __name__ == "__main__":
    main()

###############################################################################
# ì €ì‘ê¶Œ ì£¼ì˜ ë¬¸êµ¬
###############################################################################
"""
íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì €ì‘ê¶Œì— ìœ ì˜í•´ì•¼ í•˜ë©°, ìš°ë¦¬ëŠ” ì´ ì½”ë“œì˜ ì‚¬ìš© ë˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ”
ì–´ë– í•œ ì†í•´, ì˜¤ìš©, ì €ì‘ê¶Œ ì¹¨í•´ ë¬¸ì œì— ëŒ€í•´ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
This source code is protected by copyright law. Unauthorized reproduction, distribution,
modification, or commercial use is prohibited.
It may only be used for personal, non-commercial purposes, and the source must be clearly
credited upon use. Users must be mindful of copyright when uploading files, and we are
not responsible for any damages, misuse, or copyright infringement issues arising from the use
of this code or uploaded files.
"""

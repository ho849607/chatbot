import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
# OpenAI ëª¨ë“ˆì´ ì—†ì–´ë„ Gemini APIë¡œ ëŒ€ì²´í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None
from pathlib import Path
import docx2txt
import pdfplumber
from pptx import Presentation
import random
import subprocess
import nltk
from nltk.corpus import stopwords
import google.generativeai as genai
import pathlib
import PIL.Image
import requests
from concurrent.futures import ThreadPoolExecutor

###############################################################################
# NLTK ì„¤ì • ë° ë¶ˆìš©ì–´ ì²˜ë¦¬ (ìºì‹± ì ìš©)
###############################################################################
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

@st.cache_data(show_spinner=False)
def get_stopwords():
    try:
        sw = stopwords.words("english")
    except LookupError:
        nltk.download("stopwords", download_dir=nltk_data_dir)
        sw = stopwords.words("english")
    return set(sw)

english_stopwords = get_stopwords()
korean_stopwords = {"ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ë”"}
final_stopwords = english_stopwords.union(korean_stopwords)

###############################################################################
# í™˜ê²½ ë³€ìˆ˜ ë° API í‚¤ ì„¤ì •
###############################################################################
dotenv_path = Path(".env")
load_dotenv(dotenv_path=dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
USE_GEMINI_ALWAYS = os.getenv("USE_GEMINI_ALWAYS", "False").lower() == "true"

# OpenAI APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ê±°ë‚˜ USE_GEMINI_ALWAYSê°€ Trueì´ë©´ Gemini API ì‚¬ìš©
if USE_GEMINI_ALWAYS or not OPENAI_API_KEY or OpenAI is None:
    use_gemini_always = True
else:
    use_gemini_always = False
    client = OpenAI(api_key=OPENAI_API_KEY)

###############################################################################
# OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ (í•„ìš” ì‹œ)
###############################################################################
def migrate_openai_api():
    try:
        subprocess.run(["openai", "migrate"], capture_output=True, text=True, check=True)
        st.info("OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ. ì•± ì¬ì‹œì‘ í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"API ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        st.stop()

###############################################################################
# GPT API í˜¸ì¶œ í•¨ìˆ˜ (ë¬¸ì„œ ë¶„ì„, ì§ˆë¬¸, ë§ì¶¤ë²• ìˆ˜ì •)
###############################################################################
def ask_gpt(messages, model_name="gpt-4", temperature=0.7):
    """OpenAI GPT ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜. í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ Gemini APIë¡œ ì „í™˜."""
    if use_gemini_always:
        return ask_gemini(messages, temperature=temperature)
    try:
        resp = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=temperature,
        )
        return resp.choices[0].message.content.strip()
    except Exception:
        return ask_gemini(messages, temperature=temperature)

###############################################################################
# Google Gemini API í˜¸ì¶œ í•¨ìˆ˜ (ìˆ˜ì •ëœ ë°©ì‹)
###############################################################################
def ask_gemini(messages, temperature=0.7):
    """
    Gemini API í˜¸ì¶œ í•¨ìˆ˜. ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©.
    ìµœì‹  google-generativeaiì—ì„œëŠ” Completion.create()ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        prompt = messages[-1]["content"] if messages else ""
        response = genai.Completion.create(
            model="gemini-2.0-flash",  # í•„ìš”ì— ë”°ë¼ ëª¨ë¸ ì´ë¦„ ì¡°ì •
            prompt=prompt,
            temperature=temperature
        )
        return response.result.strip()
    except Exception as e:
        st.error(f"ğŸš¨ Google Gemini API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ""

###############################################################################
# ë¬¸ì„œ ë° ì´ë¯¸ì§€ íŒŒì‹± í•¨ìˆ˜ (ìºì‹± ì ìš©)
###############################################################################
@st.cache_data(show_spinner=False)
def parse_docx(file_bytes):
    try:
        return docx2txt.process(BytesIO(file_bytes))
    except Exception:
        return "ğŸ“„ DOCX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

@st.cache_data(show_spinner=False)
def parse_pdf(file_bytes):
    text_list = []
    try:
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text_list.append(page.extract_text() or "")
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PDF íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

@st.cache_data(show_spinner=False)
def parse_ppt(file_bytes):
    text_list = []
    try:
        prs = Presentation(BytesIO(file_bytes))
        for slide in prs.slides:
            for shape in slide.shapes:
                if shape.has_text_frame:
                    text_list.append(shape.text)
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PPTX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

@st.cache_data(show_spinner=False)
def analyze_image(file_bytes):
    try:
        image = PIL.Image.open(BytesIO(file_bytes))
        width, height = image.size
        return f"ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: ì´ë¯¸ì§€ í¬ê¸°ëŠ” {width}x{height} í”½ì…€ì…ë‹ˆë‹¤."
    except Exception as e:
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}"

def analyze_file(fileinfo):
    ext = fileinfo["ext"]
    data = fileinfo["data"]
    if ext == "docx":
        return parse_docx(data)
    elif ext == "pdf":
        return parse_pdf(data)
    elif ext == "pptx":
        return parse_ppt(data)
    elif ext in ["png", "jpg", "jpeg"]:
        return analyze_image(data)
    else:
        return "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (PDF, PPTX, DOCX, PNG, JPG, JPEG ì§€ì›)"

###############################################################################
# ì—¬ëŸ¬ íŒŒì¼ ë³‘í•© (ë³‘ë ¬ ì²˜ë¦¬ ì ìš©)
###############################################################################
def merge_documents(file_list):
    def process_file(file):
        file_bytes = file.getvalue()
        fileinfo = {
            "name": file.name,
            "ext": file.name.split(".")[-1].lower(),
            "data": file_bytes
        }
        return f"\n\n--- {file.name} ---\n\n" + analyze_file(fileinfo)
    
    with ThreadPoolExecutor() as executor:
        results = list(executor.map(process_file, file_list))
    return "".join(results)

###############################################################################
# GPT ë¬¸ì„œ ë¶„ì„, ì§ˆë¬¸, ë§ì¶¤ë²• ìˆ˜ì • ê¸°ëŠ¥
###############################################################################
def gpt_document_review(text):
    summary_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ íŒŒì¼ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    summary = ask_gpt(summary_prompt)
    question_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ íŒŒì¼ ë‚´ìš©ì„ ê²€í† í•˜ê³ , ì‚¬ìš©ìê°€ ìˆ˜ì •í•˜ê±°ë‚˜ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸ì„ 3ê°€ì§€ ì œì‹œí•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    questions = ask_gpt(question_prompt)
    correction_prompt = [
        {"role": "system", "content": "ì´ íŒŒì¼ì—ì„œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •í•œ ë¶€ë¶„ì„ ê°•ì¡°í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    corrections = ask_gpt(correction_prompt)
    return summary, questions, corrections

###############################################################################
# GPT/AI ì±„íŒ… ë° íŒŒì¼ ë¶„ì„ íƒ­
###############################################################################
def gpt_chat_tab():
    st.info("""
**ì‚¬ìš©ë²•**
1. PDF, PPTX, DOCX ë° ì´ë¯¸ì§€ íŒŒì¼(JPEG, PNG ë“±)ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.
2. íŒŒì¼ì˜ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.
3. AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•œ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
4. ì•„ë˜ ì±„íŒ…ì°½ì—ì„œ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    # ì—…ë¡œë“œ íŒŒì¼ íƒ€ì… í™•ì¥: ë¬¸ì„œì™€ ì´ë¯¸ì§€ íŒŒì¼ ëª¨ë‘ ì§€ì›
    uploaded_files = st.file_uploader(
        "ğŸ“ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF, PPTX, DOCX, PNG, JPG, JPEG ì§€ì›)",
        type=["pdf", "pptx", "docx", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )
    if uploaded_files is not None and len(uploaded_files) > 0:
        with st.spinner("ğŸ“– ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¶„ì„ ì¤‘..."):
            document_text = merge_documents(uploaded_files)
            summary, questions, corrections = gpt_document_review(document_text)
            st.session_state.document_text = document_text
            st.session_state.summary = summary
            st.session_state.questions = questions
            st.session_state.corrections = corrections
    if "document_text" in st.session_state:
        st.subheader("ğŸ“Œ ë¶„ì„ ê²°ê³¼")
        st.write(st.session_state.summary)
        st.write(st.session_state.questions)
        st.write(st.session_state.corrections)
    st.warning("ì£¼ì˜: AI ëª¨ë¸ì€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.subheader("ğŸ’¬ AIì™€ ëŒ€í™”í•˜ê¸°")
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="chat_input")
    if st.button("ì „ì†¡"):
        if user_input.strip():
            if "document_text" in st.session_state:
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                chat_prompt = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©: " + st.session_state.document_text},
                    {"role": "user", "content": user_input}
                ]
                ai_response = ask_gpt(chat_prompt)
                st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
            else:
                st.error("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        else:
            st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            st.write(f"**ì‚¬ìš©ì**: {message['content']}")
        else:
            st.write(f"**AI**: {message['content']}")

###############################################################################
# ì»¤ë®¤ë‹ˆí‹° íƒ­
###############################################################################
def community_tab():
    st.header("ğŸŒ ì»¤ë®¤ë‹ˆí‹° (íŒŒì¼ ê³µìœ  ë° í† ë¡ )")
    st.info("""
    **[ì»¤ë®¤ë‹ˆí‹° ì‚¬ìš©ë²•]**
    1. ìƒë‹¨ì˜ ê²€ìƒ‰ì°½ì—ì„œ ì œëª© ë˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ê¸°ì¡´ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. 'ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±' ì˜ì—­ì—ì„œ ì œëª©, ë‚´ìš© ë° íŒŒì¼(ì§€ì› íŒŒì¼: PDF, PPTX, DOCX, ì´ë¯¸ì§€)ì„ ì²¨ë¶€í•˜ì—¬ ê²Œì‹œê¸€ì„ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3. ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸° ì˜ì—­ì—ì„œ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ“ê¸€ ì‘ì„± ì‹œ ì„ì˜ì˜ 'ìœ ì €_ìˆ«ì'ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
    """)
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ (ì œëª© ë˜ëŠ” ë‚´ìš© ì…ë ¥)")
    if "community_posts" not in st.session_state:
        st.session_state.community_posts = []
    st.subheader("ğŸ“¤ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±")
    title = st.text_input("ì œëª©")
    content = st.text_area("ë‚´ìš©")
    uploaded_files = st.file_uploader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "pptx", "docx", "png", "jpg", "jpeg"], accept_multiple_files=True)
    if st.button("âœ… ê²Œì‹œê¸€ ë“±ë¡"):
        if title.strip() and content.strip():
            files_info = []
            if uploaded_files:
                for uf in uploaded_files:
                    file_bytes = uf.getvalue()
                    ext = uf.name.split(".")[-1].lower()
                    files_info.append({"name": uf.name, "ext": ext, "data": file_bytes})
            new_post = {"title": title, "content": content, "files": files_info, "comments": []}
            st.session_state.community_posts.append(new_post)
            st.success("âœ… ê²Œì‹œê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("ì œëª©ê³¼ ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    st.subheader("ğŸ“œ ê²Œì‹œê¸€ ëª©ë¡")
    for idx, post in enumerate(st.session_state.community_posts):
        if not search_query or search_query.lower() in post["title"].lower() or search_query.lower() in post["content"].lower():
            with st.expander(f"{idx+1}. {post['title']}"):
                st.write(post["content"])
                comment = st.text_input(f"ğŸ’¬ ëŒ“ê¸€ ì‘ì„± (ì‘ì„±ì: ìœ ì €_{random.randint(100,999)})", key=f"comment_{idx}")
                if st.button("ëŒ“ê¸€ ë“±ë¡", key=f"comment_btn_{idx}"):
                    if comment.strip():
                        post["comments"].append(f"ğŸ“ ìœ ì €_{random.randint(100,999)}: {comment}")
                    else:
                        st.error("ëŒ“ê¸€ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                for c in post["comments"]:
                    st.write(c)

###############################################################################
# ë©”ì¸ ì‹¤í–‰
###############################################################################
def main():
    st.title("ğŸ“š ThinkHelper - ìƒê°ë„ìš°ë¯¸")
    st.markdown("""
    **ì´ ì•±ì€ íŒŒì¼ ì—…ë¡œë“œì™€ AI ê¸°ë°˜ ë¬¸ì„œ ë° ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**
    
    - **GPT ë¬¸ì„œ ë¶„ì„ íƒ­:**  
      PDF, PPTX, DOCX ë° ì´ë¯¸ì§€ íŒŒì¼(JPEG, PNG ë“±)ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ íŒŒì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.  
      íŒŒì¼ì˜ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.  
      AIê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•œ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    - **ì»¤ë®¤ë‹ˆí‹° íƒ­:**  
      ê²Œì‹œê¸€ ë“±ë¡, ê²€ìƒ‰, ëŒ“ê¸€ ê¸°ëŠ¥ì„ í†µí•´ íŒŒì¼ì„ ê³µìœ í•˜ê³  í† ë¡ í•©ë‹ˆë‹¤.
    """)
    tab = st.sidebar.radio("ğŸ” ë©”ë‰´ ì„ íƒ", ("GPT ë¬¸ì„œ ë¶„ì„", "ì»¤ë®¤ë‹ˆí‹°"))
    if tab == "GPT ë¬¸ì„œ ë¶„ì„":
        gpt_chat_tab()
    else:
        community_tab()

if __name__ == "__main__":
    main()

st.markdown("""
---
**ì €ì‘ê¶Œ ì£¼ì˜ ë¬¸êµ¬**

- **ì½”ë“œ ì‚¬ìš©**: ì´ ì†ŒìŠ¤ ì½”ë“œëŠ” ì €ì‘ê¶Œë²•ì— ì˜í•´ ë³´í˜¸ë©ë‹ˆë‹¤. ë¬´ë‹¨ ë³µì œ, ë°°í¬, ìˆ˜ì • ë˜ëŠ” ìƒì—…ì  ì‚¬ìš©ì€ ê¸ˆì§€ë©ë‹ˆë‹¤. ê°œì¸ì , ë¹„ìƒì—…ì  ìš©ë„ë¡œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš© ì‹œ ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œê¸°í•´ì•¼ í•©ë‹ˆë‹¤.
- **íŒŒì¼ ì—…ë¡œë“œ**: ì‚¬ìš©ìëŠ” íŒŒì¼ì„ ì—…ë¡œë“œí•  ë•Œ ì €ì‘ê¶Œì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì €ì‘ê¶Œ ì¹¨í•´ ë¬¸ì œê°€ ë°œìƒí•  ê²½ìš°, ë³¸ ì„œë¹„ìŠ¤ëŠ” ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
""")

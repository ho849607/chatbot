import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
import openai
from pathlib import Path
import docx2txt
import pdfplumber
from pptx import Presentation
import random
import subprocess

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

###############################################################################
# NLTK ì„¤ì • (ë¶ˆìš©ì–´ ìë™ ë‹¤ìš´ë¡œë“œ)
###############################################################################
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

try:
    stopwords.words("english")
except LookupError:
    nltk.download("stopwords", download_dir=nltk_data_dir)

korean_stopwords = ["ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ë”"]
english_stopwords = set(stopwords.words("english"))
final_stopwords = english_stopwords.union(set(korean_stopwords))

###############################################################################
# í™˜ê²½ ë³€ìˆ˜ & OpenAI API ì„¤ì •
###############################################################################
dotenv_path = Path(".env")
load_dotenv(dotenv_path=dotenv_path)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("ğŸš¨ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

openai.api_key = OPENAI_API_KEY

###############################################################################
# OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ (ì˜ˆì „ ë²„ì „ í˜¸í™˜ - í•„ìš” ì‹œ)
###############################################################################
def migrate_openai_api():
    try:
        subprocess.run(["openai", "migrate"], capture_output=True, text=True, check=True)
        st.info("OpenAI API ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ. ì•± ì¬ì‹œì‘ í›„ ì‚¬ìš©í•˜ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"API ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        st.stop()

###############################################################################
# GPT API í˜¸ì¶œ í•¨ìˆ˜ (ë¬¸ì„œ ë¶„ì„ & ì§ˆë¬¸ & ë§ì¶¤ë²• ìˆ˜ì •)
###############################################################################
def ask_gpt(messages, model_name="gpt-4", temperature=0.7):
    """GPT ëª¨ë¸ê³¼ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜"""
    try:
        resp = openai.ChatCompletion.create(
            model=model_name,
            messages=messages,
            temperature=temperature,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        error_message = str(e)
        if "no longer supported" in error_message:
            migrate_openai_api()
        st.error(f"ğŸš¨ OpenAI API í˜¸ì¶œ ì—ëŸ¬: {e}")
        return ""

###############################################################################
# ë¬¸ì„œ ë¶„ì„ í•¨ìˆ˜ (PDF, PPTX, DOCX)
###############################################################################
def parse_docx(file_bytes):
    """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        return docx2txt.process(BytesIO(file_bytes))
    except Exception:
        return "ğŸ“„ DOCX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_pdf(file_bytes):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    text_list = []
    try:
        with pdfplumber.open(BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                text_list.append(page.extract_text() or "")
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PDF íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def parse_ppt(file_bytes):
    """PPTX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    text_list = []
    try:
        prs = Presentation(BytesIO(file_bytes))
        for slide in prs.slides:
            for shape in slide.shapes:
                if shape.has_text_frame:
                    text_list.append(shape.text)
        return "\n".join(text_list)
    except Exception:
        return "ğŸ“„ PPTX íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜"

def analyze_file(fileinfo):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¶„ì„"""
    ext = fileinfo["ext"]
    data = fileinfo["data"]
    if ext == "docx":
        return parse_docx(data)
    elif ext == "pdf":
        return parse_pdf(data)
    elif ext == "pptx":
        return parse_ppt(data)
    else:
        return "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."

###############################################################################
# GPT ë¬¸ì„œ ë¶„ì„ & ì§ˆë¬¸ & ìˆ˜ì • ê¸°ëŠ¥
###############################################################################
def gpt_document_review(text):
    """GPTê°€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½, ì§ˆë¬¸ ë° ìˆ˜ì •"""
    # 1. ë¬¸ì„œ ìš”ì•½ ìš”ì²­
    summary_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    summary = ask_gpt(summary_prompt)

    # 2. ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
    question_prompt = [
        {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê²€í† í•˜ê³ , ì‚¬ìš©ìê°€ ìˆ˜ì •í•˜ê±°ë‚˜ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸ì„ 3ê°€ì§€ ì œì‹œí•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    questions = ask_gpt(question_prompt)

    # 3. ë§ì¶¤ë²• ë° ë¬¸ì¥ ìˆ˜ì • ìš”ì²­
    correction_prompt = [
        {"role": "system", "content": "ì´ ë¬¸ì„œì—ì„œ ë§ì¶¤ë²•ê³¼ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •í•œ ë¶€ë¶„ì„ ê°•ì¡°í•˜ì„¸ìš”."},
        {"role": "user", "content": text}
    ]
    corrections = ask_gpt(correction_prompt)

    return summary, questions, corrections

###############################################################################
# GPT ì±„íŒ… + ë¬¸ì„œ ë¶„ì„ íƒ­
###############################################################################
def gpt_chat_tab():
    # ì‚¬ìš©ë²• ì•ˆë‚´ ë¶€ë¶„ ìˆ˜ì •: ìƒë‹¨ì— "ì‚¬ìš©ë²•"ë§Œ í‘œì‹œí•˜ê³ , ì•„ë˜ì— ë¶€ì—° ì„¤ëª…ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    st.info("""
**ì‚¬ìš©ë²•**

1ï¸âƒ£ PDF/PPTX/DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
2ï¸âƒ£ ë¬¸ì„œì˜ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.
3ï¸âƒ£ GPTê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    """)

    uploaded_files = st.file_uploader(
        "ğŸ“ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/PPTX/DOCX ì§€ì›)",
        type=["pdf", "pptx", "docx"],
        accept_multiple_files=False
    )

    if uploaded_files:
        file_bytes = uploaded_files.getvalue()
        fileinfo = {
            "name": uploaded_files.name,
            "ext": uploaded_files.name.split(".")[-1].lower(),
            "data": file_bytes
        }
        with st.spinner(f"ğŸ“– {fileinfo['name']} ë¶„ì„ ì¤‘..."):
            document_text = analyze_file(fileinfo)
            # GPT ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰
            summary, questions, corrections = gpt_document_review(document_text)
            st.subheader("ğŸ“Œ ë¬¸ì„œ ìš”ì•½")
            st.write(summary)
            st.subheader("ğŸ’¡ ê³ ë ¤í•´ì•¼ í•  ì§ˆë¬¸")
            st.write(questions)
            st.subheader("âœï¸ ë§ì¶¤ë²• ë° ë¬¸ì¥ ìˆ˜ì •")
            st.write(corrections)

###############################################################################
# ì»¤ë®¤ë‹ˆí‹° íƒ­
###############################################################################
def community_tab():
    st.header("ğŸŒ ì»¤ë®¤ë‹ˆí‹° (ë¬¸ì„œ ê³µìœ  ë° í† ë¡ )")
    st.info("""
    **[ì»¤ë®¤ë‹ˆí‹° ì‚¬ìš©ë²•]**
    1. ìƒë‹¨ì˜ ê²€ìƒ‰ì°½ì—ì„œ ì œëª© ë˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•˜ì—¬ ê¸°ì¡´ ê²Œì‹œê¸€ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2. 'ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±' ì˜ì—­ì—ì„œ ì œëª©, ë‚´ìš© ë° íŒŒì¼(PDF/PPTX/DOCX ì§€ì›)ì„ ì²¨ë¶€í•˜ì—¬ ê²Œì‹œê¸€ì„ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3. ê²Œì‹œê¸€ ìƒì„¸ë³´ê¸° ì˜ì—­ì—ì„œ ëŒ“ê¸€ì„ ì‘ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ“ê¸€ ì‘ì„± ì‹œ ì„ì˜ì˜ 'ìœ ì €_ìˆ«ì'ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.
    """)
    
    search_query = st.text_input("ğŸ” ê²€ìƒ‰ (ì œëª© ë˜ëŠ” ë‚´ìš© ì…ë ¥)")

    if "community_posts" not in st.session_state:
        st.session_state.community_posts = []

    st.subheader("ğŸ“¤ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì‘ì„±")
    title = st.text_input("ì œëª©")
    content = st.text_area("ë‚´ìš©")
    uploaded_files = st.file_uploader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "pptx", "docx"], accept_multiple_files=True)

    if st.button("âœ… ê²Œì‹œê¸€ ë“±ë¡"):
        if title.strip() and content.strip():
            files_info = []
            if uploaded_files:
                for uf in uploaded_files:
                    file_bytes = uf.getvalue()
                    ext = uf.name.split(".")[-1].lower()
                    files_info.append({"name": uf.name, "ext": ext, "data": file_bytes})
            new_post = {"title": title, "content": content, "files": files_info, "comments": []}
            st.session_state.community_posts.append(new_post)
            st.success("âœ… ê²Œì‹œê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

    st.subheader("ğŸ“œ ê²Œì‹œê¸€ ëª©ë¡")
    for idx, post in enumerate(st.session_state.community_posts):
        if search_query.lower() in post["title"].lower() or search_query.lower() in post["content"].lower():
            with st.expander(f"{idx+1}. {post['title']}"):
                st.write(post["content"])
                comment = st.text_input(f"ğŸ’¬ ëŒ“ê¸€ ì‘ì„± (ì‘ì„±ì: ìœ ì €_{random.randint(100,999)})", key=f"comment_{idx}")
                if st.button("ëŒ“ê¸€ ë“±ë¡", key=f"comment_btn_{idx}"):
                    post["comments"].append(f"ğŸ“ ìœ ì €_{random.randint(100,999)}: {comment}")
                for c in post["comments"]:
                    st.write(c)

###############################################################################
# ë©”ì¸ ì‹¤í–‰
###############################################################################
def main():
    st.title("ğŸ“š ThinHelper - ìƒê°ë„ìš°ë¯¸")

    st.markdown("""
    **ì´ ì•±ì€ íŒŒì¼ ì—…ë¡œë“œì™€ GPT ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**
    
    - **GPT ë¬¸ì„œ ë¶„ì„ íƒ­:**  
      1. PDF/PPTX/DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.  
      2. ë¬¸ì„œ ìš”ì•½, ìˆ˜ì •í•  ë¶€ë¶„, ê·¸ë¦¬ê³  ê°œì„ ì„ ìœ„í•œ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.  
      3. GPTê°€ ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ì—¬ ê°œì„ ëœ ë¬¸ì„œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    - **ì»¤ë®¤ë‹ˆí‹° íƒ­:**  
      ê²Œì‹œê¸€ ë“±ë¡, ê²€ìƒ‰, ëŒ“ê¸€ ê¸°ëŠ¥ì„ í†µí•´ ë¬¸ì„œë¥¼ ê³µìœ í•˜ê³  í† ë¡ í•©ë‹ˆë‹¤.
    """)

    tab = st.sidebar.radio("ğŸ” ë©”ë‰´ ì„ íƒ", ("GPT ë¬¸ì„œ ë¶„ì„", "ì»¤ë®¤ë‹ˆí‹°"))
    if tab == "GPT ë¬¸ì„œ ë¶„ì„":
        gpt_chat_tab()
    else:
        community_tab()

if __name__ == "__main__":
    main()

###############################################################################
# ì €ì‘ê¶Œ ì£¼ì˜ ë¬¸êµ¬ (Copyright Notice)
###############################################################################
"""
íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì €ì‘ê¶Œì— ìœ ì˜í•´ì•¼ í•˜ë©°, ìš°ë¦¬ëŠ” ì´ ì½”ë“œì˜ ì‚¬ìš© ë˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì–´ë– í•œ ì†í•´, ì˜¤ìš©, ì €ì‘ê¶Œ ì¹¨í•´ ë¬¸ì œì— ëŒ€í•´ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.

This source code is protected by copyright law. Unauthorized reproduction, distribution, modification, or commercial use is prohibited. 
It may only be used for personal, non-commercial purposes, and the source must be clearly credited upon use. 
Users must be mindful of copyright when uploading files, and we are not responsible for any damages, misuse, or copyright infringement issues arising from the use of this code or uploaded files.
"""
